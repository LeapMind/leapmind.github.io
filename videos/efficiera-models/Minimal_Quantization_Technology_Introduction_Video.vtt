WEBVTT

00:00:00.000 --> 00:00:08.000
リープマインド株式会社より、独自のディープラーニングモデル圧縮手法、極小量子化技術について紹介いたします。

00:00:09.000 --> 00:00:21.000
近年、ディープラーニングは身近な存在になり、スマートフォン、スマートスピーカーなどの多くのIoTデバイスのバックエンドで利用され、私たちの生活をより便利なものに変えています。

00:00:22.000 --> 00:00:33.000
また、IoTデバイスの市場規模は着実に成長し、数年にはデバイスの数も、扱うデータの量も爆発的に増加すると予想されています。

00:00:34.000 --> 00:00:44.000
この膨大な量のデータをクラウドに集約させて処理することは、データセンター等の能力の限界があり、次第に困難になっていくと考えられます。

00:00:45.000 --> 00:00:55.000
そこで、クラウドではなく、デバイス上でディープラーニングによる推論処理を行う、いわゆるエッジディープラーニングの需要が拡大していくと我々は考えています。

00:00:56.000 --> 00:01:02.000
エッジディープラーニングは基本的にインターネットを介した通信を行わないことが特徴のため、

00:01:03.000 --> 00:01:18.000
通信の帯域幅やレイテンシー、信頼性に依存しないこと、外部にデータを送信しないことからセキュリティ面のリスクが少ないこと、さらに通信やクラウド利用のコストが削減できるといったメリットがあります。

00:01:19.000 --> 00:01:29.000
そのため、通信の安定しない環境でもリアルタイムな応答が必要とされたり、個人情報を扱うような場面においての活用が期待されています。

00:01:30.000 --> 00:01:34.000
しかし、エッジディープラーニングの実用化にはいくつかの課題があります。

00:01:35.000 --> 00:01:42.000
その一つが、デバイス上で利用できる処理能力、電力などの計算資源が制限されてしまう問題、

00:01:43.000 --> 00:01:51.000
そして、その限られた計算資源では、演算量の多さと推論の処理速度はトレードオフの関係になるという問題です。

00:01:52.000 --> 00:02:06.000
ディープラーニングで用いられるニューラルネットワークでは、数値計算、行列演算が繰り返し膨大な量を行われていますが、ここで使われているで他は浮動小数点数という、少数点を含む数値の場合があります。

00:02:07.000 --> 00:02:18.000
そのような桁数の多い数字の演算は複雑になるため、処理能力の低いデバイスでは、演算量が増えれば増えるほど処理速度が低下してしまうのです。

00:02:19.000 --> 00:02:28.000
リープマインドでは、これらの問題の解決策の一つとして、極小量子化という独自技術の研究開発を続けてきました。

00:02:29.000 --> 00:02:41.000
極小量子化技術とは、ディープラーニングモデル圧縮最適化手法の一つ、量子化を極限まで突き詰めたもので、演算量などのエッジディープラーニングの抱える問題を解決できます。

00:02:42.000 --> 00:02:54.000
そもそもディープラーニングにおける量子化とは、ディープラーニングモデルを構成するパラメーターなどの大量の数値を精度の高い連続した数値表現である浮動小数点数から、

00:02:55.000 --> 00:03:03.000
8ビット整数などのより低ビットで離散的な数値表現に近似して置き換えることで、モデルサイズを軽量化する手法です。

00:03:04.000 --> 00:03:13.000
ただし、量子化にはビット幅を小さくするほどモデルが軽くなる代わりに、推論の精度が劣化してしまうという課題があります。

00:03:14.000 --> 00:03:23.000
一般に、通常用いられる32ビット浮動小数点数から8ビット整数への量子化では、ある程度の精度を保てますが、

00:03:24.000 --> 00:03:28.000
それ未満では精度劣化が顕著に現われてしまうことが知られています。

00:03:29.000 --> 00:03:35.000
リープマインドの開発する極小量子化技術は、この精度劣化を最小限にとどめつつ、

00:03:36.000 --> 00:03:43.000
これ以上量子化ビット数を減らしてしまうと、ディープラーニングとして成立しない限界まで量子化を行う技術です。

00:03:44.000 --> 00:03:55.000
具体的には、鵜ウェイト学習済みモデルのパラメータを1ビット、アクティベーション、推論処理途中の演算結果を2ビットにまで低ビット化して表現しています。

00:03:56.000 --> 00:04:03.000
また、推論精度に与える影響が大きいことが知られていたニューラルネットワークの第一層の量子化も、

00:04:04.000 --> 00:04:10.000
リープマインドが開発した入力データの変換手法、ピクセルエンディングで可能にしています。

00:04:11.000 --> 00:04:17.000
この手法は、言語処理の分野で使われるワードエンベディングの考え方を応用して考案されました。

00:04:18.000 --> 00:04:29.000
極小量子化技術を適用したディープラーニングモデルは、量子化していないものに比べ、およそ99パーセントもの大幅なサイズの圧縮を達成しています。

00:04:30.000 --> 00:04:35.000
また、推論精度の劣化は、このグラフの示す通り、最小限に抑えることが可能です。

00:04:36.000 --> 00:04:43.000
ここまで極端な軽量化にも関わらず、制度維持に成功している理由の一つが、学習時の工夫にあります。

00:04:44.000 --> 00:04:54.000
一般的な量子化技術では、浮動小数点数で学習したモデルに、あとから量子化を適用して推論に使用する方法が取られます。

00:04:55.000 --> 00:05:01.000
この場合、既存の学習済みモデルをそのまま使いますが、8ビット未満の量子化では精度が低下してしまいます。

00:05:02.000 --> 00:05:11.000
リープマインドでは、専用の学習環境を用意し、学習の段階から量子化を行うことで推論精度を高く保つことを可能にしています。

00:05:12.000 --> 00:05:22.000
その為、極小量子化技術は学習済みのモデルには適用できず、データセットを用意してディープラーニングモデルの学習を行う必要があります。

00:05:23.000 --> 00:05:31.000
開発に労力はかかりますが、その分、極小量子化技術が実用時にもたらすメリットは非常に大きなものがあります。

00:05:32.000 --> 00:05:35.000
極小量子化技術のメリットは大きく二つあります。

00:05:36.000 --> 00:05:43.000
一つは、モデルサイズが小さくなることで、デバイスのメモリ消費を大幅に削減できること、

00:05:44.000 --> 00:05:52.000
そして浮動小数点演算を簡単なビット演算に近似することで、通常は膨大な量になる演算を減らせることです。

00:05:53.000 --> 00:06:05.000
これらのメリットは、省電力化や演算回路規模の省面積化につながるため、制約が多いエッジデバイス上での高速なディープラーニング、推論処理を実現する鍵となります。

00:06:06.000 --> 00:06:14.000
極小量子化技術は、エッジディープラーニングを実現するために必要な工程を逆算して生まれた、最も効率的な技術なのです。

00:06:15.000 --> 00:06:27.000
リープマインドでは、この極小量子化技術を最大限に生かすため、超低消費電力AI推論アクセラレータIP、エフィシエラを開発いたしました。

00:06:28.000 --> 00:06:38.000
極小量子化技術とエフィシエラを組み合わせることで、電力効率と面積効率を最大化し、AI搭載製品の迅速な市場投入を可能にします。

00:06:39.000 --> 00:06:44.000
エフィシエラの詳細は、リープマインドの公式ウェブサイトよりご確認いただけます。

00:06:45.000 --> 00:06:55.000
リープマインドは、極小量子化技術とエフィシエラ、ソフトウェアとハードウェアの両面から、エッジ領域におけるAIの実用化を推進してまいります。